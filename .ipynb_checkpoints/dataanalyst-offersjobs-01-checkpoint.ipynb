{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import DataSet 'Data Analyst Jobs'"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# IMPORT DATA AND PACKED\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\npd.options.plotting.backend = 'plotly'\nplt.style.use('seaborn')\ninit_notebook_mode(connected = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/data-analyst-jobs/DataAnalyst.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning to be Wokerd On"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delete column \"Unnamed: 0\"\ndf.drop(['Unnamed: 0'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy data a new DataFrame\ndf1 = df.copy()\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############################################### DATA CLEANING #############################################################\n\ndf1['Job Title'],df1['Department']= df['Job Title'].str.split(',',1).str\ndf1['Company Name'],_ = df['Company Name'].str.split('\\n',1).str\ndf1['Salary Estimate'],_= df['Salary Estimate'].str.split('(',1).str\ndf1['Min Salary'],df1['Max Salary']= df1['Salary Estimate'].str.split('-').str\n\n# Created values Max Salary and Min Salary as well as data cleaning with  strip methods from string class\ndf1['Min Salary'] = df1['Min Salary'].replace('', np.nan) # Replace withe spaces for nan values through the numpy\ndf1['Max Salary'] = df1['Max Salary'].replace('', np.nan)\ndf1['Min Salary'] = df1['Min Salary'].str.strip().str.lstrip('$').str.rstrip('K').fillna(0).astype(int)\ndf1['Max Salary'] = df1['Max Salary'].str.strip().str.lstrip('$').str.rstrip('K').fillna(0).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show 'df1' with the changes realized before \ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Empty Field 'Salary Estimate' but created Max and Min salary before.\ndf1 = df1.drop(['Salary Estimate'],axis = 1)\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################################################ DATA ANALYTICS ##########################################################\n# Count values from easy apply for each job offers\ndf1['Easy Apply'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Companies Easy Apply for Data Analyst Jobs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Easy applicated only 80 companies, the rest could to be applicated dificult it.\n# With function, it recode key and values to take a new values between 0 and 1\ndef recode(column, new_code):\n    col_cod = pd.Series(column, copy = True)\n    for key, values in new_code.items():\n        col_cod.replace(key, values, inplace = True)\n    return col_cod","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use new fuction\ndf1['Easy Apply'] = recode(df1['Easy Apply'],{'-1':0,'True':1})\ndf1['Competitors'] = recode(df1['Competitors'],{'-1':np.nan})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracted data the Easy Apply with values equal '1', in the other words,  this part  will to make only in offers jobs where is easy applicated\ndf_easy_apply = df1[df1['Easy Apply']==1]\ndf_easy_apply.reset_index()\ndf_easy_apply.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New Dataframe through method 'Groupby' from 'pandas' packet. It's grouped in fallen order and count the values \"Easy Apply\" for each offer jobs\ndf_easy_apply_1 = df_easy_apply.groupby('Company Name')['Easy Apply'].count().reset_index()\ndf_easy_apply_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply order descendent for dataframe before and perform cut in ten primary\ndf_easy = df_easy_apply_1.sort_values('Easy Apply', ascending = False).head(10).reset_index().drop('index', axis = 1)\ndf_easy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot grafic from DataFrom 'Easy Apply' for each company\nplt.figure(figsize=(12,5))\n\nchart = sns.barplot(data = df_easy, x = 'Company Name', y = 'Easy Apply')\nchart = chart.set_xticklabels(chart.get_xticklabels(),\n                             rotation = 60,\n                             horizontalalignment = 'right',\n                             fontweight = 'light')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Size Company - Employed Quantity that Offer Jobs as a Data Analyst**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now, visualization of size company in funtion quantily employees that offers job in data analyst.\n\n# Create DateFrame:\ndf_employed = df1['Size'].value_counts().to_frame().reset_index()\ndf_employed.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Empty rows with useless data\ndf_employed = df_employed.drop([6,8], axis = 0)\ndf_employed.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change of field names for easy descriptive in graphic and visualization\ndf_employed = df_employed.rename(columns = {'index': 'Size Company - Employees Quantity',\n                                            'Size': 'Nº Company'})\ndf_employed.shape\ndf_employed.head(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finally, plot graphic barplot in horizontal for Size Company in function of employees Quantity:\n# Use Seaborn\nplt.figure(figsize = (10,6))\n\nplot = sns.barplot(x = 'Nº Company', y = 'Size Company - Employees Quantity', data = df_employed)\nplot = plot.set_xticklabels(plot.get_xticklabels(),\n                           rotation = 65,\n                           horizontalalignment = 'right',\n                           fontweight = 'light')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification of Companies vs Ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use grouby method for get a new dataframe thad measure number companies your rating.\ndf_rating = df1.groupby('Rating')['Company Name'].count().to_frame().reset_index()\n# the order descending in the ratings function\ndf_rating = df_rating.sort_values('Rating', ascending = False).reset_index()\ndf_rating = df_rating.drop(['index'], axis = 1)\ndf_rating.shape\ndf_rating.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cut dataframe size, the only values that generate interesting is rating up at latest 3.0\ndf_rating = df_rating.iloc[:21,:]\ndf_rating.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename fields for this columns.\ndf_rating = df_rating.rename(columns = {'Company Name': 'Nº Companies'})\ndf_rating.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot visualization in graphic bars. \nplt.figure(figsize = (12,6))\n\nplot = sns.barplot(x = 'Rating', y = 'Nº Companies', data = df_rating)\nplot = plot.set_xticklabels(plot.get_xticklabels(),\n                           horizontalalignment = 'right',\n                           fontweight = 'light')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ownership Companies Type that Offers Jobs Data Analyst"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization of Ownerships companies type that offers job Data Analyst\ndf_ownership = df1['Type of ownership'].value_counts().to_frame()\ndf_ownership.head(15)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Empty row with '-1\ndf_ownership = df_ownership.drop('-1').reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename columns for their graphic\ndf_ownership = df_ownership.rename(columns = {'index': 'Type of Ownership','Type of ownership': 'Nº Offers Jobs'})\ndf_ownership.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cut data until the row 9th\ndf_ownership = df_ownership.iloc[:9,:]\ndf_ownership.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finaly, barplot with seaborn\nplt.figure(figsize = (12,6))\nplot = sns.barplot(x = 'Nº Offers Jobs', y = 'Type of Ownership', data = df_ownership)\nplot = plot.set_xticklabels(plot.get_xticklabels(),\n                           rotation = 65,\n                           horizontalalignment = 'right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Range Salary for Each Sector"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now, analyze Max salary in fuction the each sector\ndf_max_salary = df1.groupby(['Sector']).mean().reset_index()\ndf_max_salary.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Eliminate rows innesesary \ndf_max_salary = df_max_salary.drop([0,10,17,16], axis = 0)\ndf_max_salary = df_max_salary.drop(['Founded','Easy Apply'], axis = 1)\ndf_max_salary.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Order values in funtion 'Max Salary' and drop 'index'\ndf_max_salary = df_max_salary.sort_values('Max Salary', ascending = False).reset_index()\ndf_max_salary = df_max_salary.drop('index', axis = 1)\ndf_max_salary.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization in bar graph with plotly\n\n# Create Trace 1\ntrace1 = go.Bar(x = df_max_salary['Sector'],\n                y = df_max_salary['Max Salary'],\n                name = 'Max Salary',\n                marker = dict(color ='rgb(55, 83, 109)',\n                             line = dict(color = 'rgb(0,0,0)', width = 1.5)))\n\n# Create Trace 2\ntrace2 = go.Bar(x = df_max_salary['Sector'],\n                y = df_max_salary['Min Salary'],\n                name = 'Min Salary',\n                marker = dict(color = 'indianred',\n                             line = dict(color = 'rgb(0,0,0)', width = 1.5)))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(title = 'Salary Range For Each Sector', \n                   barmode = 'group')\n\nchart = go.Figure(data = data, layout = layout)\niplot(chart)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of Job Offers as a Data Analyst in the Territory of the United States"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a DataFrame with features (Mean Salary, Location and Mean Salary) \ndf_states = pd.DataFrame()\ndftemp = df1.copy()\ndftemp['Mean Salary'] = (df1['Max Salary'] + df1['Min Salary']) / 2\ndf_states = pd.concat([df1['Sector'],df1['Location'], dftemp['Mean Salary']], axis = 1)\ndf_states.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperate Acronym and City from Location Field\ndf_states['City'], df_states['Acronym State'] = df_states['Location'].str.split(',', 1).str\n# Remove field \"Location\":\ndf_states = df_states.drop('Location', axis = 1)\n# Remove values '-1' into field \"Sector\":\ndf_states = df_states.drop(df_states[df_states['Sector'] == '-1'].index, axis = 0)\ndf_states.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply Groupy with DataFrame both in the count and the mean values, after concated fields in the new DataFrame:\ndf_states_group = df_states.groupby(['Acronym State']).count().reset_index()\ndf_salary_group = df_states.groupby(['Acronym State']).mean().reset_index()\n# New Dataframe \ndf_map = pd.DataFrame()\ndf_map = pd.concat([df_states_group['Acronym State'], df_states_group['Sector'], df_salary_group['Mean Salary']], axis = 1)\ndf_map.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Round Mean Salary Value with Lambda function and remove row in 'Araphone, CO' Value of \"Sector\" field\ndf_map = df_map.drop([1], axis = 0)\ndf_map['Mean Salary'] = df_map['Mean Salary'].apply(lambda x: round(x, 2))\n# Rename Field\ndf_map = df_map.rename(columns = {'Sector': 'Nº Offers Jobs'})\ndf_map.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot Map of United States with Plotly in module graph_objects:\nlocations = list(df_map['Acronym State'])\n\n# Remove withe space in \"Acronym State\" field\nfor i in range(0, len(locations)):\n    locations[i] = locations[i].replace(\" \", \"\")\n\nqjobs = list(df_map['Nº Offers Jobs'])\n\n# Create text that displays the basic data when the cursor is over the chart status \ndf_map_str = df_map.copy()\nfor col in df_map_str.columns:\n    df_map_str[col] = df_map_str[col].astype(str)\n    \n# Apply '$' symbol in Mean Salary values\ndf_map_str['Mean Salary'] = df_map_str['Mean Salary'].apply(lambda x: \"$\" + x + \"/Year\")\n# Text visualization:\ndf_map_str['Text'] = df_map_str['Acronym State']  + '<br>' + \\\n    \"Nª Offers Jobs: \" + df_map_str['Nº Offers Jobs'] + '<br>' \\\n        \"Mean Salary from the Jobs as Data Analyst: \" + '<br>' + df_map_str['Mean Salary']\ndf_map_str.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot Map in plotly\nimport plotly.graph_objects as go\n\n\nfig = go.Figure(data = go.Choropleth(locations = locations,\n                                    z = qjobs,\n                                    locationmode = 'USA-states',\n                                    text = df_map_str['Text'],\n                                    marker_line_color = 'black',\n                                    colorbar_title = 'Nº Offers Jobs'),) \n\nfig.update_layout(title_text = 'Nº Offers Jobs as Data Analyst<br>United States of America',\n                 geo = dict(scope = 'usa',\n                           projection = go.layout.geo.Projection(type = 'albers usa'),\n                           showlakes = True,\n                           lakecolor = 'rgb(255,255,255)'),)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cluster Analysis (K-Means) and PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A cluster study is performed in a data frame for the data in order to find similarities\n# In addition, this is supported with PCA study\n# Import Library\nfrom sklearn.decomposition import PCA # For PCA dimensionality reduction\nfrom sklearn.cluster import KMeans    # Method for Cluster Kmeans\nfrom sklearn.preprocessing import QuantileTransformer #Realize Scaler Data\n# For visualization from 3D plot\nimport plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Data Frame with \"Mean Salary, Founded Years and Rating\" for cluster method and PCA\ndf2 = df1.copy()\ndf2 = df2.drop(df2[df2['Founded'] == -1].index)\ndf2 = df2.drop(df2[df2['Rating'] == -1].index)\ndf2['Years Founded'] = (2020 - df2['Founded'])\ndf2['Mean Salary'] = (df2['Max Salary'] + df2['Min Salary']) / 2\n\n# Create DataFrame\ndf3 = pd.DataFrame()\ndf3 = pd.concat([df2['Rating'], df2['Mean Salary'], df2['Years Founded']], axis = 1)\ndf3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rescale values with QuantileTransformer class\ndf3_scaler = QuantileTransformer().fit_transform(df3)\nprint(df3_scaler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PCA calculation is performed with a reduction of dimensionality equal to 2\npca = PCA(n_components = 2)\ndf_component = pca.fit_transform(df3_scaler)\nprint(df_component.shape, df3_scaler.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The number cluster is determined\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', n_init = 10, \n                   max_iter = 300, random_state = 0)\n    kmeans.fit(df3_scaler)\n    wcss.append(kmeans.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot curve inertian cluster\nfig = plt.figure(figsize = (8,7))\nplt.plot(range(1,11), wcss)\nplt.scatter(3, wcss[2], c = 'red',s = 200)\nplt.text(3 + 0.4, wcss[2], s = '3 - Clusters', fontsize = 14)\nplt.xlabel('Nº Clusters', fontsize = 14)\nplt.ylabel('Inertian Infraclusters', fontsize = 14)\nplt.title('Elbow Method', fontsize = 14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4 clusters are selected, at that elbow point an optimized cluster can be achieved.\nkmeans = KMeans(n_clusters = 3, init = 'k-means++', n_init = 10, \n                max_iter = 300, random_state = 0)\nkmeans.fit(df3_scaler)\ny_predict = kmeans.predict(df3_scaler)\nprint(y_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First one, 3D visualization are better for show clusters calculated\n\nfig3d = px.scatter_3d(df3, x = 'Rating', y = 'Mean Salary', z = 'Years Founded', color = y_predict,\n                     opacity = 0.80, size_max = 8)\n\nfig3d.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n\nfig3d.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Graph PCA component with cluster predict\ndfsns = pd.DataFrame(df_component)\n# Rename Columns:\ndfsns = dfsns.rename(columns = {0: 'Component 1', 1: 'Component 2'})\n\n#Plot with Seaborn\nsns.set_style('darkgrid')\nsns.relplot(x = 'Component 1', y = 'Component 2', hue = y_predict, data = dfsns, palette= 'Dark2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_predict = pd.DataFrame(y_predict)\ndf_predict = df_predict.rename(columns = {0 : 'Cluster'})\ndf_predict.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataframe with cluster classification\ndf3_scaler = pd.DataFrame(df3_scaler)\ndf3_scaler = df3_scaler.rename(columns = {0: 'Rating', 1: 'Mean Salary', 2: 'Years Founded'})\ndf3_scaler['Cluster'] = df_predict['Cluster']\ndf3_scaler['Cluster'] = recode(df3_scaler['Cluster'], \n                               {0: 'Cluster-1', \n                                1: 'Cluster-2', \n                                2: 'Cluster-3'})\ndf3_scaler.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Groupby apply\ndf_cluster_group = df3_scaler.groupby('Cluster').mean()\ndf_cluster_group.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Graph scatter bar for each cluster number\n# Scaler values\n\ncolors = ['#CF8EF8', '#523C81', '#D2D132']\ny = np.array(df_cluster_group)\nplt.figure(1, figsize = (18,8))\n#Cluster 1\nplt.subplot(1,3,1)\nvalue = y[:1,:].tolist()[0]\nplt.bar(range(len(value)), height = value, width = 1/1.5, color = colors)\nplt.xticks(range(df_cluster_group.shape[1]),df_cluster_group.columns)\n#Cluster 2\nplt.subplot(1,3,2)\nvalue = y[1:2,:].tolist()[0]\nplt.bar(range(len(value)), height = value, width = 1/1.5, color = colors)\nplt.xticks(range(df_cluster_group.shape[1]),df_cluster_group.columns)\n#Cluster 3\nplt.subplot(1,3,3)\nvalue = y[2:3,:].tolist()[0]\nplt.bar(range(len(value)), height = value, width = 1/1.5, color = colors)\nplt.xticks(range(df_cluster_group.shape[1]),df_cluster_group.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(max(df2['Mean Salary']))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}